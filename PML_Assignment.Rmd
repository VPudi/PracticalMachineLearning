---
title: "Practical Machine Learning-Assignment"
author: "Venkatesh Pudipeddi"
date: "September 15, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview

The goal of this assignment is to do a predictive analysis of a data set obtained from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. 
The data for this analysis was obtained from the following links:

The training data for this analysis is available here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data is available here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

We will perform some data clean up and build some prediction models using R's caret package to predict the "classe"
variable on the text dataset of 20 test cases.

### Data Loading and Cleanup

```{r PML}
library(caret)
library(ggplot2)
library(rattle)
library(rpart)

pml_train <- read.csv("C:\\Users\\Venkatesh\\Documents\\Coursera\\Practical Machine Learning\\CourseProject\\pml-training.csv")

pml_test <- read.csv("C:\\Users\\Venkatesh\\Documents\\Coursera\\Practical Machine Learning\\CourseProject\\pml-testing.csv")

str(pml_train[,1:30])

```

From the above, we can see that there are around 160 variables in the dataset and 19K observations. 
We also see that there are a lot of variables with NAs or blanks and so we can eliminate them as they 
will not help in the prediction modeling. We can also remove the first 7 cols which are basically names
and timestamps which are not useful for modeling.

```{r cleanup}
# find variables with 90% NAs or blank values
badcols <- which(colSums(is.na(pml_train) | pml_train == "") > 0.9 * nrow(pml_train))
new_train <- pml_train[,-badcols]
# remove the first 7 columns
new_train <- new_train[,-c(1:7)]

## cleanup of test dataset

badcols2 <- which(colSums(is.na(pml_test) | pml_test == "") > 0.9 * nrow(pml_test))
new_test <- pml_test[,-badcols2]
# remove the first 7 columns
new_test <- new_test[,-c(1:7)]

# create a partition of the traning data set 
set.seed(9301)
ds1 <- createDataPartition(new_train$classe, p=0.75, list=FALSE)
dsTrain <- new_train[ds1, ]
dsTest <- new_train[-ds1, ]

dim(dsTrain)

```
We have reduced the variables to just 53. We can use these 53 variables in our prediction modeling.

### Prediction Model Building

Since the prediction we want to do is that of classification of the type of exercise performed into A, B, C, D, E
we will use the caret package's classification algorithms like Random Forests, classification tree and gradient boosting methods to build the models and compare the accuracy of the models in predicting the "classe" variable.

We will also use the caret packages k-fold cross validation algorithims to train the models.

#### Model 1: Classification Tree

```{r model1, cache=TRUE}
# 5-fold cross validation
kcv <- trainControl(method="cv", number=5)
model1 <- train(classe ~ ., data = dsTrain, method = "rpart", trControl = kcv)

predict1 <- predict(model1, newdata = dsTest)

cm1 <- confusionMatrix(dsTest$classe, predict1)

cm1$overall["Accuracy"]
cm1$table
fancyRpartPlot(model1$finalModel)

```

We can see that the accuracy with this model is around 56% and so not very accurate. We will explore other models.

#### Model 2: Random Forests

```{r model2, cache=TRUE}
model2 <- train(classe ~ ., data = dsTrain, method = "rf", trControl = kcv, verbose = FALSE)
predict2 <- predict(model2, newdata = dsTest)

cm2 <- confusionMatrix(dsTest$classe, predict2)

cm2$overall["Accuracy"]
cm2$table

plot(model2$finalModel)
```

#### Model 3: GBM - Gradient Boosting Method
```{r model3, cache=TRUE}

model3 <- train(classe ~ ., data = dsTrain, method = "gbm", trControl=kcv, verbose = FALSE)
predict3 <- predict(model3, newdata = dsTest)

cm3 <- confusionMatrix(dsTest$classe, predict3)

cm3$overall["Accuracy"]
cm3$table
plot(model3)
```

### Conclusion

From the above three model accuracies, we can see that the Random Forests model predicts with the highest accuracy of 99.2%.
The next best model is the GBM model with 96%.

We can use this RF model(model2) to predict on the original Test dataset with 20 test cases.

```{r final, cache=TRUE}

FinalPrediction <- predict(model2, new_test)

FinalPrediction
```
